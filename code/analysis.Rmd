---
title: "Empirical results"
author: "Jacob Toner Gosselin"
---

# Load libraries and data

```{r}
# load libraries
library(dplyr)
library(tidyr)
library(readxl)
library(fixest)
source("../code/helper_fncts.R")

# load data
load("../data/cleaned/resid_data_1998_2023.RData") # load api data
# remove NaNs 
resid_data_clean <- resid_data_1998_2023 %>%
  filter(!is.na(delta_1) & !is.infinite(delta_1))

# generate industry_year factor
resid_data_clean$industry_year <- factor(paste(resid_data_clean$Code, resid_data_clean$year, sep = "-"))
resid_data_clean$input_year <- factor(paste(resid_data_clean$j, resid_data_clean$year, sep = "-"))
```

# Main results

## Estimation
```{r}
library(fixest)

# load data
load("../data/cleaned/resid_data_1998_2023.RData") # load non-api data
# remove NaNs (log changes involving 0 spending)
resid_data_clean <- resid_data_1998_2023 %>%
  filter(!is.na(delta_1) & !is.infinite(delta_1))

# generate industry_year factor
resid_data_clean$industry_year <- factor(paste(resid_data_clean$Code, resid_data_clean$year, sep = "-"))
resid_data_clean$input_year <- factor(paste(resid_data_clean$j, resid_data_clean$year, sep = "-"))

# run residualizing regression
mod_main <- feols(delta_1 ~ delta_logPj_1:Code | industry_year, data = resid_data_clean)
mod_main_sum <- summary(mod_main, vcov_cluster("industry_year"))

# store residuals 
resid_results <- resid_data_clean
resid_results$resid <- mod_main$residuals

# save estimates
save(mod_main, mod_main_sum, resid_results, file = "../data/cleaned/main_results.RData")
```

## Plot thetas
```{r}
load("../data/cleaned/main_results.RData")
library(ggplot2)
library(dplyr)
library(tidyr)

coef_names <- names(coef(mod_main_sum))
theta_i <- as.data.frame(mod_main_sum$coefficients[grep("delta_logPj_1:", coef_names, value = TRUE)])
colnames(theta_i) <- "beta"
theta_i$coef <- rownames(theta_i)
theta_i <- separate(theta_i, coef, into = c("term", "Code"), sep = ":")
theta_i$theta <- 1 - theta_i$beta
theta_i$se <- mod_main_sum$se[grep("delta_logPj_1:", coef_names, value = TRUE)]
theta_i$Code <- gsub("Code", "", theta_i$Code)
# generate counter for Code
theta_i$Code_lab <- as.numeric(factor(theta_i$Code, levels = unique(theta_i$Code)))

# plot theta_i +/- 1 SE for each Code
theta_i_plot <- ggplot(theta_i, aes(x = Code_lab, y = theta)) +
  geom_point() +
  geom_errorbar(aes(ymin = theta - 1.65*se, ymax = theta + 1.65*se), width = 0.2) +
  theme_minimal() +
  labs(title = "", x = "", y = expression(~theta[i])) + # suppress xlabel
  theme(text = element_text(family = "serif", size = 24)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_hline(yintercept = 1, linetype = "dashed") +
  # count every 10
  scale_x_continuous(breaks = seq(0, max(theta_i$Code_lab), by = 10), labels = seq(0, max(theta_i$Code_lab), by = 10)) 
  

ggsave("../figures/elasticity_est/elasticities_main.pdf", theta_i_plot, width = 16, height = 9)

# save theta_i table
load("../data/cleaned/code_desc_crosswalk.RData")
theta_i_tab <- merge(theta_i, code_desc_crosswalk, by = "Code")
theta_i_tab <- theta_i_tab %>% 
  rename("Industry" = "Industry Description") %>%
  mutate(Elasticity = round(theta, 3), 
         SE = round(se, 3),
         Industry = ifelse(nchar(Industry) > 50, paste(substr(Industry, 1, 50), "...", sep=""), Industry),
         Code = Code_lab) %>%
  select(Code, Industry, Elasticity, SE)

# write as long table to latex
write.table(theta_i_tab, file = "../tables/elasticities_main.tex", sep = " & ", row.names = FALSE, col.names = FALSE, quote = FALSE, eol = " \\\\\n")
```

## Local projections
```{r}
library(lpirfs)
library(dplyr)
library(ggplot2)

# load BEA + Patents data
load("../data/cleaned/patent_data_agg.RData")

# we have to use Code_patent, to account for multiple Codes mapping to some NAICS 3-digit 
resid_results$delta_1_resid <- resid_results$resid
temp <- resid_results[, c("Code", "year", "delta_1", "delta_1_resid")]
panel_data <- temp %>%
  group_by(Code, year) %>%
  summarise(
    sum_delta_1 = sum(abs(delta_1), na.rm = TRUE),
    sum_delta_1_resid = sum(abs(delta_1_resid), na.rm = TRUE)
  )

panel_data <- merge(panel_data, patent_data_agg, by = c("Code", "year"), all.x = TRUE, all.y = TRUE)
panel_data <- panel_data[, c("Code", "year", "sum_delta_1", "sum_delta_1_resid", "patents_xi_real", "patents_num", "patents_cites")]

# local projections
patents_value_lp_og <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_xi_real", confint = 1, hor = 15, cumul_mult = FALSE)
patents_value_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_xi_real", confint = 1, hor = 15, cumul_mult = FALSE)
patents_citations_lp_og <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_cites", confint = 1, hor = 15, cumul_mult = FALSE)
patents_citations_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_cites", confint = 1, hor = 15, cumul_mult = FALSE)

# plot and save
patents_value_lp_both <- graph_lp_both(patents_value_lp_og, patents_value_lp_resid)
patents_citations_lp_both <- graph_lp_both(patents_citations_lp_og, patents_citations_lp_resid)

patents_value_lp <- graph_lp_one(patents_value_lp_resid, "resid")
patents_citations_lp <- graph_lp_one(patents_citations_lp_resid, "resid")

ggsave("../figures/local_projections/patents_value_resid.pdf", patents_value_lp, width = 9, height = 9)
ggsave("../figures/local_projections/patents_citations_resid.pdf", patents_citations_lp, width = 16, height = 9)
```

# Atalay comparison

```{r}
library(texreg)
library(tidyr)
library(dplyr)

# load Atalay data
load("../data/cleaned/atalay_instruments.RData")

# merge 
atalay_comparison <- merge(resid_data_clean, atalay_instruments, by = c("Code", "year", "j"))
top_10_subset <- resid_data_clean %>%
  group_by(Code, year) %>%
  top_n(10, val) %>%
  filter(year < 2014)
atalay_comparison_subset <- merge(top_10_subset, atalay_instruments, by = c("Code", "year", "j"))

# run IV regression
atalay_IV <- feols(delta_1 ~ 1 | Code + year | delta_logPratio_1_II ~ military_shock_i + military_shock_j + military_shock_suppliers, data = atalay_comparison)
atalay_comp <- feols(delta_1 ~ delta_logPj_1 | industry_year, data = atalay_comparison)
atalay_IV_subset <- feols(delta_1_Out ~ 1 | Code + year | delta_logPratio_1_II + delta_logPratio_1_IIOut ~ military_shock_i +  military_shock_j + military_shock_suppliers, data = atalay_comparison_subset)
atalay_comp_subset <- feols(delta_1 ~ delta_logPj_1 | industry_year, data = atalay_comparison_subset)

# texreg output
# use cluster robust SEs
atalay_IV_sum_robust <- summary(atalay_IV, vcov = "hetero")
atalay_comp_sum_robust <- summary(atalay_comp, vcov = "hetero")
atalay_IV_sum_cluster <- summary(atalay_IV, vcov_cluster("industry_year"))
atalay_comp_sum_cluster <- summary(atalay_comp, vcov_cluster("industry_year"))
atalay_IV_sum_subset_robust <- summary(atalay_IV_subset, vcov = "hetero")
atalay_comp_sum_subset_robust <- summary(atalay_comp_subset, vcov = "hetero")
atalay_IV_sum_subset_cluster <- summary(atalay_IV_subset, vcov_cluster("industry_year"))
atalay_comp_sum_subset_cluster <- summary(atalay_comp_subset, vcov_cluster("industry_year"))

# texreg results
# override coef, use 1-coefficient
coef_map <- list(
  "delta_logPj_1" = "Elasticity",
  "fit_delta_logPratio_1_II" = "Elasticity"
)

texreg(list(atalay_comp_sum_robust, atalay_IV_sum_robust, atalay_comp_sum_cluster, atalay_IV_sum_cluster), custom.coef.map = coef_map, custom.model.names = c("Uniform", "Atalay IV", "Uniform", "Atalay IV"), custom.header = list("Robust SE" = 1:2, "Clustered SE" = 3:4), include.rsquared = FALSE, include.adjrs = FALSE, table = FALSE, file = "../tables/atalay_comparison.tex", override.coef = list(1 - atalay_comp_sum_robust$coefficients, 1 - atalay_IV_sum_robust$coefficients, 1 - atalay_comp_sum_cluster$coefficients, 1 - atalay_IV_sum_cluster$coefficients), include.nobs=FALSE, include.groups=FALSE, stars = numeric(0))

coef_map <- list(
  "delta_logPj_1" = "Elasticity (inner-nest)",
  "fit_delta_logPratio_1_II" = "Elasticity (inner-nest)",
  "fit_delta_logPratio_1_IIOut" = "Elasticity (outer-nest)"
)

# texreg(list(atalay_comp_sum_subset_robust, atalay_IV_sum_subset_robust, atalay_comp_sum_subset_cluster,  atalay_IV_sum_subset_cluster), custom.coef.map = coef_map, custom.model.names = c("Uniform", "Atalay IV", "Uniform", "Atalay IV"), custom.header = list("Robust SE" = 1:2, "Clustered SE" = 3:4), include.rsquared = FALSE, include.adjrs = FALSE, table = FALSE, file = "../tables/atalay_comparison_subset.tex", override.coef = list(1 - atalay_comp_sum_subset_robust$coefficients, 1 - atalay_IV_sum_subset_robust$coefficients,1 - atalay_comp_sum_subset_cluster$coefficients, 1 - atalay_IV_sum_subset_cluster$coefficients), include.nobs=FALSE, include.groups=FALSE, stars = numeric(0))
```

# Industry-year results

Here I permit elasticities to vary by industry-year. 

## Estimation
```{r}
library(fixest)
library(lmtest)

# run residualizing regression
model_delta_1 <- feols(delta_1 ~ delta_logPj_1:industry_year | industry_year, data = resid_data_clean)
model_delta_1_sum <- summary(model_delta_1)

# store residuals 
resid_results <- resid_data_clean
resid_results$delta_1_resid <- model_delta_1$residuals

save(resid_results, model_delta_1_sum, file = "../data/cleaned/resid_results_1998_2023.RData")
```

## Plot thetas

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

load("../data/cleaned/resid_results_1998_2023.RData")

coef_names <- names(coef(model_delta_1_sum))
theta_it <- as.data.frame(model_delta_1_sum$coefficients[grep("delta_logPj_1:", coef_names, value = TRUE)])
colnames(theta_it) <- "beta"
theta_it$coef <- rownames(theta_it)
# split Code into 2 columns by :
theta_it <- separate(theta_it, coef, into = c("term", "Code"), sep = ":")
theta_it <- separate(theta_it, Code, into = c("Code", "year"), sep = "-")
theta_it$Code <- gsub("industry_year", "", theta_it$Code)
theta_it$theta <- 1 - theta_it$beta
theta_it$year <- as.numeric(theta_it$year) 

# check percent in 0-1
perc_in_01 <- sum(theta_it$theta >= 0 & theta_it$theta <= 1) / nrow(theta_it)

# ggplot histogram of theta
theta_hist <- ggplot(theta_it, aes(x = theta)) +
  geom_histogram(binwidth = 0.1, fill = "black", alpha = 0.5) +
  theme_minimal() +
  labs(title = "", x = expression(~theta[i]), y = "Frequency") +
  theme(text = element_text(family = "serif", size = 32))

# calculate percent in 0-1
sum(theta_it$theta >= 0 & theta_it$theta <= 1) / nrow(theta_it)

# collapse mean and sd of theta by year
theta_collapsed_Year = theta_it %>%
  group_by(year) %>%
  summarise(mean_theta = mean(theta),
            sd_theta = sd(theta))

# collapse mean and SD of theta by Code
theta_collapsed_Code = theta_it %>%
  group_by(Code) %>%
  summarise(mean_theta = mean(theta),
            sd_theta = sd(theta))

# Plots

theta_mean_SD_plot_byYear <- ggplot(theta_collapsed_Year, aes(x = year, y = mean_theta)) +
  geom_line(color = "black") +  # Add a line for the mean
  geom_ribbon(aes(ymin = mean_theta - sd_theta, ymax = mean_theta + sd_theta), alpha = 0.2, fill = "black") +  # Add shaded region for SD
  geom_point() +  # Add points for the mean
  theme_minimal() + 
  theme(text = element_text(family = "serif", size = 24)) +
  labs(x = "", y = "", title = "") + 
  geom_hline(yintercept = 0, linetype = "dashed") + geom_hline(yintercept = 1, linetype = "dashed") + 
  ylim(-2.5, 2)

theta_mean_SD_plot_byCode <- ggplot(theta_collapsed_Code, aes(y = Code, x = mean_theta)) +
  geom_errorbarh(aes(xmin = mean_theta - sd_theta, xmax = mean_theta + sd_theta), height = 0.2) +
  geom_point() +
  theme_minimal() + 
  theme(axis.text.y = element_blank(), text = element_text(family = "serif", size = 24)) +
  labs(y = "Year", x = expression(~theta[i]), title = "") + 
  geom_vline(xintercept = 0, linetype = "dashed") + 
  geom_vline(xintercept = 1, linetype = "dashed")

# do the same plot as above but horizontal (Code x-axis, theta y-axis)
theta_mean_SD_plot_byCode_h <- ggplot(theta_collapsed_Code, aes(x = Code, y = mean_theta)) +
  geom_errorbar(aes(ymin = mean_theta - sd_theta, ymax = mean_theta + sd_theta), width = 0.2) +
  geom_point() +
  theme_minimal() + 
  theme(axis.text.x = element_blank(), text = element_text(family = "serif", size = 24)) +
  labs(x = "", y = "", title = "") + 
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_hline(yintercept = 1, linetype = "dashed") + 
  ylim(-2.5, 2)

# save individual figures
# ggsave("../figures/elasticity_est/elasticity_byYear.pdf", theta_mean_SD_plot_byYear, width = 9, height = 9)
# ggsave("../figures/elasticity_est/elasticity_byCode.pdf", theta_mean_SD_plot_byCode, width = 9, height = 9)

# save joint figures
library(ggpubr)
combined <- ggarrange(theta_mean_SD_plot_byYear, theta_mean_SD_plot_byCode_h, ncol = 2, nrow = 1)
ggsave("../figures/elasticity_est/elasticities_IndustryYear.pdf", combined, width = 16, height = 9)

# save results
save(theta_collapsed_Code, theta_collapsed_Year, file = "../data/cleaned/elasticity_ests_IndustryYear.RData")
```

## Local projections

```{r}
library(lpirfs)
library(dplyr)
library(ggplot2)

# load residuals data
load("../data/cleaned/resid_results_1998_2023.RData")
# load BEA + Patents data
load("../data/cleaned/patent_data_agg.RData")

# we have to use Code_patent, to account for multiple Codes mapping to some NAICS 3-digit 
temp <- resid_results[, c("Code", "year", "delta_1", "delta_1_resid")]
panel_data <- temp %>%
  group_by(Code, year) %>%
  summarise(
    sum_delta_1 = sum(abs(delta_1), na.rm = TRUE),
    sum_delta_1_resid = sum(abs(delta_1_resid), na.rm = TRUE)
  )

panel_data <- merge(panel_data, patent_data_agg, by = c("Code", "year"), all.x = FALSE, all.y = TRUE)
panel_data <- panel_data[, c("Code", "year", "sum_delta_1", "sum_delta_1_resid", "patents_xi_real", "patents_num", "patents_cites")]

# local projections
patents_value_lp_og <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_xi_real", confint = 1, hor = 10, cumul_mult = FALSE)
patents_value_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_xi_real", confint = 1, hor = 10, cumul_mult = FALSE)
patents_citations_lp_og <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_cites", confint = 1, hor = 10, cumul_mult = FALSE)
patents_citations_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_method = "white1", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_cites", confint = 1, hor = 10, cumul_mult = FALSE)

# plot and save
patents_value_lp_both <- graph_lp_both(patents_value_lp_og, patents_value_lp_resid)
patents_citations_lp_both <- graph_lp_both(patents_citations_lp_og, patents_citations_lp_resid)

patents_value_lp <- graph_lp_one(patents_value_lp_resid, "resid")
patents_citations_lp <- graph_lp_one(patents_citations_lp_resid, "resid")

ggsave("../figures/local_projections/patents_value_resid.pdf", patents_value_lp, width = 9, height = 9)
ggsave("../figures/local_projections/patents_citations_resid.pdf", patents_citations_lp, width = 16, height = 9)
```

# Misc

## Fracking

```{r}
library(lpirfs)
library(dplyr)
library(ggplot2)
library(readxl)

# load residuals data
load("../data/cleaned/resid_results_1998_2023.RData")
shale_prod <- read_excel("../data/raw/misc/shale_prod.xls", 
    sheet = "Data 1", skip = 2)
# extract year from date
shale_prod$year <- as.numeric(format(as.Date(shale_prod$Date), "%Y"))

panel_data <- resid_results %>%
  group_by(Code, year) %>%
  summarise(
    sum_delta_1 = sum(abs(delta_1), na.rm = TRUE),
    sum_delta_1_resid = sum(abs(delta_1_resid), na.rm = TRUE)
  )
oil_gas_extraction <- subset(panel_data, Code == "211")

fracking <- merge(oil_gas_extraction, shale_prod, by = "year")
fracking$log_delta_prod <- log(fracking$`U.S. Shale Production (Billion Cubic Feet)`) - log(lag(fracking$`U.S. Shale Production (Billion Cubic Feet)`))
# get correlation, removing NAs
cor(fracking$sum_delta_1_resid, fracking$log_delta_prod, use = "pairwise.complete.obs")
```

