}
get_resid_elast <- function(data){
# define inputs
dat <- data
group_low = min(dat$year)
group_max = max(dat$year)
group = paste(group_low, group_max, sep = "-")
dat$year_group <- group
dat$industry_year <- factor(paste(dat$Code, dat$year, sep = "_")) # generate industry-year in fnct; don't do it beforehand, it messes with feols
dat$industry <- factor(dat$Code)
# run main regression
mod <- feols(delta_1 ~ industry_year + delta_logPratio_1_II:industry, data = dat)
# store residuals
dat$resid <- mod$residuals
resid_ests <- dat[, c("year", "year_group", "Code", "j", "resid")]
# Recover theta ests
coef_names <- names(coef(mod))
estimates <- coef(mod)[grep("delta_logPratio_1_II", coef_names)]
estimates <- as.data.frame(estimates)
estimates$term <- rownames(estimates)
estimates$Code <- gsub("delta_logPratio_1_II:industry", "", estimates$term)
intervals <- confint(mod, parm = grep("delta_logPratio_1_II", coef_names, value = TRUE))
intervals_df <- as.data.frame(intervals)
intervals_df$term <- rownames(intervals_df)
colnames(intervals_df) <- c("lower", "upper", "term")
intervals_df <- merge(intervals_df, estimates, by = "term")
intervals_df$upper_theta <- 1 - intervals_df$lower
intervals_df$lower_theta <- 1 - intervals_df$upper
intervals_df$theta <- 1 - intervals_df$estimate
theta_est <- intervals_df
theta_est$year_group <- group
return(list(theta_est = theta_est, resid_ests = resid_ests, mod))
}
get_mean_elasticity <- function(data) {
dat = data
group_low = min(dat$year)
group_max = max(dat$year)
group = paste(group_low, group_max, sep = "-")
dat$industry_year <- factor(paste(dat$Code, dat$year))
mod = feols(delta_1 ~ industry_year + delta_logPratio_1_II, data = dat)
estimate <- coef(mod)["delta_logPratio_1_II"]
se <- summary(mod, cluster = ~industry_year)$se["delta_logPratio_1_II"]
estimate_lower <- estimate - 1.645*se
estimate_upper <- estimate + 1.645*se
theta = 1 - estimate
theta_lower = 1 - estimate_upper
theta_upper = 1 - estimate_lower
return(data.frame(year_group = group, estimate = estimate, se = se, estimate_lower = estimate_lower, estimate_upper = estimate_upper, theta = theta, lower_theta = theta_lower, upper_theta = theta_upper))
}
library(tidyr)
library(fixest)
library(lpirfs)
library(ggplot2)
library(dplyr)
resid_data_1999_2023_clean <- resid_data_1999_2023 %>%
filter(!is.na(delta_1) & !is.na(delta_logPratio_1_II) & !is.infinite(delta_1))
resid_data_1999_2023_clean$year <- as.numeric(resid_data_1999_2023_clean$year)
# generate 5-year groups
resid_data_1999_2023_clean$year_group <- cut(resid_data_1999_2023_clean$year, breaks = seq(1998, 2023, 5))
# get results
main_results_1999_2023 <- lapply(split(resid_data_1999_2023_clean, resid_data_1999_2023_clean$year_group), get_resid_elast)
resid_est_1999_2023 <- lapply(main_results_1999_2023, function(x) x$resid_ests)
resid_est_1999_2023_long <- do.call(rbind, resid_est_1999_2023)
theta_est_1999_2023 <- lapply(main_results_1999_2023, function(x) x$theta_est)
theta_est_1999_2023_long <- do.call(rbind, theta_est_1999_2023)
main_results_1999_2023_long <- merge(resid_est_1999_2023_long, theta_est_1999_2023_long, by = c("Code", "year_group"))
# get overall elasticity by year group
overall_theta_est_1999_2023 <- lapply(split(resid_data_1999_2023_clean, resid_data_1999_2023_clean$year_group), get_mean_elasticity)
overall_theta_est_1999_2023_df <- do.call(rbind, overall_theta_est_1999_2023)
load("../data/cleaned/patent_data_agg.RData")
load("../data/cleaned/summary_naics_crosswalk.RData")
# we have to use Code_patent, to account for multiple Codes mapping to some NAICS 3-digit
temp <- resid_est_1999_2023_long[, c("Code", "year", "resid")]
temp <- merge(temp, summary_naics_crosswalk, by = "Code")
panel_data <- temp %>%
group_by(Code_patent, year) %>%
summarise(
sum_resid = sum(abs(resid), na.rm = TRUE)
)
panel_data <- merge(panel_data, patent_data_agg, by = c("Code_patent", "year"), all.x = TRUE, all.y = FALSE)
panel_data <- panel_data[, c("Code_patent", "year", "sum_resid", "patents_xi_real", "patents_num", "patents_cites")]
# local projections
patents_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_resid", shock = "patents_xi_real", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_resid_alt <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_resid", shock = "patents_cites", confint = 1.65, hor = 15, cumul_mult = FALSE)
# plot and save
patents_lp <- graph_lp_one(patents_lp_resid, "resid")
patents_lp_alt <- graph_lp_one(patents_lp_resid_alt, "resid")
ggsave("../figures/local_projections/patents_lp_resid_theta5.pdf", patents_lp, width = 9, height = 9)
ggsave("../figures/local_projections/patents_lp_resid_alt_theta5.pdf", patents_lp_alt, width = 16, height = 9)
patents_lp
# elasticity plot function
plot_elast_coef <- function(data) {
year = unique(data$year_group)
plot <- ggplot(data, aes(x = term, y = 0)) +
geom_errorbar(aes(ymin = lower_theta, ymax = upper_theta), width = 0.2) +
geom_point(aes(y = theta)) +
labs(x = expression(~theta[i]),
y = "Confidence Interval",
color = "Includes Zero", title = year) + theme_minimal() +
theme(axis.text.x = element_blank(), text = element_text(family = "serif", size = 24), legend.position = "none") +
geom_hline(yintercept = 0, linetype = "dashed") +
geom_hline(yintercept = 1, linetype = "dashed")
return(plot)
}
# apply theta_ests list
elasticity_coef_plots <- lapply(split(theta_est_1999_2023_long, theta_est_1999_2023_long$year_group), plot_elast_coef)
for (i in 1:length(elasticity_coef_plots)) {
ggsave(paste0("../figures/elasticity_est/elasticity_byInd_", names(elasticity_coef_plots)[i], ".pdf"), elasticity_coef_plots[[i]], width = 16, height = 9)
}
overall_theta_plot_1999_2023 <- ggplot(overall_theta_est_1999_2023_df, aes(x = year_group, y = theta)) +
geom_errorbar(aes(ymin = lower_theta, ymax = upper_theta), width = 0.2) +
geom_point() +
labs(x = "", y = expression(~theta[i]), title = "") +
theme_minimal() + theme(text = element_text(family = "serif", size = 24))
ggsave("../figures/elasticity_est/mean_elasticity_5yr_1999-2023.pdf", overall_theta_plot_1999_2023, width = 16, height = 9)
log_omega_est <- merge(resid_est_1999_2023_long, theta_est_1999_2023_long, by = c("Code", "year_group"))
log_omega_est$log_omega <- log_omega_est$resid/log_omega_est$theta
log_omega_est <- subset(log_omega_est, theta > 0)
# local projections
temp <- log_omega_est[, c("Code", "year", "log_omega")]
temp <- merge(temp, summary_naics_crosswalk, by = "Code")
panel_data <- temp %>%
group_by(Code_patent, year) %>%
summarise(
sum_log_omega = sum(abs(log_omega), na.rm = TRUE)
)
panel_data <- merge(panel_data, patent_data_agg, by = c("Code_patent", "year"), all.x = TRUE, all.y = FALSE)
panel_data <- panel_data[, c("Code_patent", "year", "sum_log_omega", "patents_xi_real", "patents_num", "patents_cites")]
# local projections
patents_lp_logomega <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_log_omega", shock = "patents_xi_real", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_logomega_alt <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_log_omega", shock = "patents_cites", confint = 1.65, hor = 15, cumul_mult = FALSE)
# plot and save
patents_lp_omega <- graph_lp_one(patents_lp_logomega, "resid")
patents_lp_omega_alt <- graph_lp_one(patents_lp_logomega_alt, "resid")
ggsave("../figures/local_projections/patents_lp_resid_theta5.pdf", patents_lp, width = 9, height = 9)
ggsave("../figures/local_projections/patents_lp_resid_alt_theta5.pdf", patents_lp_alt, width = 16, height = 9)
patents_lp_omega
patents_lp_omega_alt
# load libraries
library(dplyr)
library(tidyr)
library(readxl)
library(fixest)
source("../code/helper_fncts.R")
# load data
load("../data/cleaned/resid_data_1999_2023_api.RData") # load non-api data
# remove NaNs
resid_data_clean <- resid_data_1999_2023 %>%
filter(!is.na(delta_1) & !is.infinite(delta_1))
# generate industry_year factor
resid_data_clean$industry_year <- factor(paste(resid_data_clean$Code, resid_data_clean$year, sep = "_"))
# run residualizing regression
model_delta_1 <- feols(delta_1 ~ industry_year + delta_logPratio_1_II:industry_year + logPratio_1_II:industry_year, data = resid_data_clean)
# store residuals
resid_results <- resid_data_clean
resid_results$delta_1_resid <- model_delta_1$residuals
save(resid_results, model_delta_1, file = "../data/cleaned/resid_results_1999_2023_api.RData")
library(ggplot2)
library(dplyr)
library(fixest)
library(xtable)
coef_names <- names(coef(model_delta_1))
delta_theta <- as.data.frame(coef(model_delta_1)[grep(":logPratio_1", coef_names, value = TRUE)])
colnames(delta_theta) <- "delta_theta"
theta <- as.data.frame(coef(model_delta_1)[grep(":delta_logPratio_1", coef_names, value = TRUE)])
colnames(theta) <- "theta"
# make dataframe of first quartile, median, third quartile for delta_theta and theta
quartiles <- c(0.25, 0.5, 0.75)
delta_theta_quartiles <- as.data.frame(apply(delta_theta, 2, quantile, probs = quartiles))
theta_quartiles <- as.data.frame(apply(theta, 2, quantile, probs = quartiles))
merged_quartiles <- rbind(t(delta_theta_quartiles), t(theta_quartiles))
# round values to 2 decimal places
merged_quartiles <- round(merged_quartiles, 2)
rownames(merged_quartiles) <- c("$\\alpha_{it}$", "$\\beta_{it}$")
colnames(merged_quartiles) <- c("1st Quartile", "Median", "3rd Quartile")
merged_quartiles_table <- xtable(merged_quartiles, )
print(merged_quartiles_table, floating = FALSE, file = "../tables/elasticity_quartiles_Int.tex", sanitize.text.function=function(x){x})
# plot overlapping histograms of delta_theta and theta
delta_theta <- as.data.frame(delta_theta)
theta <- as.data.frame(theta)
delta_theta$coef <- "delta_theta"
theta$coef <- "theta"
names(delta_theta) <- c("value", "coef")
names(theta) <- c("value", "coef")
combined <- rbind(delta_theta, theta)
ggplot(combined, aes(x = value, fill = coef)) +
geom_histogram(position = "identity", alpha = .25, binwidth = .1) +
theme_minimal() +
labs(title = "", x = "", y = "Frequency", fill = "") +
theme(text = element_text(family = "serif", size = 32), legend.position = "bottom") + coord_cartesian(xlim = c(-2, 2)) +
scale_fill_manual(values = c("red", "blue"), labels = c(expression(alpha[italic("it")]), expression(beta[italic("it")])))
ggsave("../figures/histograms/elasticity_coef_hist.pdf", width = 16, height = 9)
library(lpirfs)
library(dplyr)
library(ggplot2)
# load residuals data
# load("../data/cleaned/resid_data_1999_2023_api.RData")
# load BEA + Patents data
load("../data/cleaned/patent_data_agg.RData")
load("../data/cleaned/summary_naics_crosswalk.RData")
# we have to use Code_patent, to account for multiple Codes mapping to some NAICS 3-digit
temp <- resid_results[, c("Code", "year", "delta_1", "delta_1_resid")]
temp <- merge(temp, summary_naics_crosswalk, by = "Code")
panel_data <- temp %>%
group_by(Code_patent, year) %>%
summarise(
sum_delta_1 = sum(abs(delta_1), na.rm = TRUE),
sum_delta_1_resid = sum(abs(delta_1_resid), na.rm = TRUE)
)
panel_data <- merge(panel_data, patent_data_agg, by = c("Code_patent", "year"), all.x = TRUE, all.y = FALSE)
panel_data <- panel_data[, c("Code_patent", "year", "sum_delta_1", "sum_delta_1_resid", "patents_xi_real", "patents_num", "patents_cites")]
# local projections
patents_lp_og <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_xi_real", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_resid <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_xi_real", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_og_alt <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_delta_1", shock = "patents_cites", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_resid_alt <- lp_lin_panel(panel_data, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_delta_1_resid", shock = "patents_cites", confint = 1.65, hor = 15, cumul_mult = FALSE)
# plot and save
patents_lp_both <- graph_lp_both(patents_lp_og, patents_lp_resid)
patents_lp_both_alt <- graph_lp_both(patents_lp_og_alt, patents_lp_resid_alt)
patents_lp <- graph_lp_one(patents_lp_resid, "resid")
patents_lp_alt <- graph_lp_one(patents_lp_resid_alt, "resid")
ggsave("../figures/local_projections/patents_lp_Int_both.pdf", patents_lp_both, width = 16, height = 9)
ggsave("../figures/local_projections/patents_lp_Int_both_alt.pdf", patents_lp_both_alt, width = 16, height = 9)
ggsave("../figures/local_projections/patents_lp_Int_alt.pdf", patents_lp_alt, width = 16, height = 9)
ggsave("../figures/local_projections/patents_lp_Int.pdf", patents_lp, width = 9, height = 9)
patents_lp
resid_data_clean$industry <- factor(resid_data_clean$Code)
model_delta_1_alt <- feols(delta_1 ~ industry_year + delta_logPratio_1_II:industry, data = resid_data_clean)
resid_results_alt <- resid_data_clean
resid_results_alt$delta_1_resid <- model_delta_1_alt$residuals
# Extract coefficient names
coef_names <- names(coef(model_delta_1_alt))
# Extract coefficients for delta_logPratio_1_II: terms
beta <- coef(model_delta_1_alt)[grep("delta_logPratio_1_II", coef_names)]
theta_estimates <- as.data.frame(beta)
theta_estimates$term <- rownames(theta_estimates)
# separate term in 2 terms by :
theta_estimates$Code <- gsub("delta_logPratio_1_II:industry", "", theta_estimates$term)
theta_estimates$theta <- 1 - theta_estimates$beta
# Compute confidence intervals for logPratio_1:industry_year terms
intervals <- confint(model_delta_1_alt, parm = grep("delta_logPratio_1_II", coef_names, value = TRUE))
# Convert the intervals to a data frame for plotting
intervals_df <- as.data.frame(intervals)
intervals_df$term <- rownames(intervals_df)
colnames(intervals_df) <- c("lower", "upper", "term")
intervals_df <- merge(intervals_df, theta_estimates, by = "term")
# change all values in intervals_df to 1-value
intervals_df$upper_theta <- 1 - intervals_df$lower
intervals_df$lower_theta <- 1 - intervals_df$upper
intervals_df$theta <- 1 - intervals_df$beta
# Check complements or substitutes
intervals_df$complements <- intervals_df$upper_theta < 1
intervals_df$substitutes <- intervals_df$lower_theta > 1
intervals_df$sub_zero <- intervals_df$theta > 0
# Calculate the percentage of intervals that include 0
percent_comp <- mean(intervals_df$complements)
percent_sub <- mean(intervals_df$substitutes)
# Plot the confidence intervals with vertical error bars
ggplot(intervals_df, aes(x = term, y = 0)) +
geom_errorbar(aes(ymin = lower_theta, ymax = upper_theta, color = sub_zero), width = 0.2) +
geom_point(aes(y = theta, color = sub_zero)) +
labs(x = expression(~theta[i]),
y = "Confidence Interval",
color = "Includes Zero") + theme_minimal() +
theme(axis.text.x = element_blank(), text = element_text(family = "serif", size = 24), legend.position = "none")
ggsave("../figures/theory/elasticity_est_Int.pdf", width = 16, height = 9)
# generate delta_log_omega
resid_results_alt <- merge(resid_results_alt, theta_estimates, by = "Code")
resid_results_alt$log_omega <- resid_results_alt$delta_1_resid/resid_results_alt$theta
load("../data/cleaned/patent_data_agg.RData")
load("../data/cleaned/summary_naics_crosswalk.RData")
# we have to use Code_patent, to account for multiple Codes mapping to some NAICS 3-digit
temp <- resid_results_alt[, c("Code", "year", "log_omega")]
temp <- merge(temp, summary_naics_crosswalk, by = "Code")
panel_data_alt <- temp %>%
group_by(Code_patent, year) %>%
summarise(
sum_log_omega = sum(abs(log_omega), na.rm = TRUE)
)
panel_data_alt <- merge(panel_data_alt, patent_data_agg, by = c("Code_patent", "year"), all.x = TRUE, all.y = FALSE)
panel_data_alt <- panel_data_alt[, c("Code_patent", "year", "sum_log_omega", "patents_xi_real", "patents_num", "patents_cites")]
# local projections
patents_lp_omega <- lp_lin_panel(panel_data_alt, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_log_omega", shock = "patents_xi_real", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_omega_alt <- lp_lin_panel(panel_data_alt, panel_model = "within", panel_effect = "twoways", robust_cov = "vcovHC", robust_cluster = "group", diff_shock = FALSE, endog_data = "sum_log_omega", shock = "patents_cites", confint = 1.65, hor = 15, cumul_mult = FALSE)
patents_lp_omega <- graph_lp_one(patents_lp_omega, "resid")
patents_lp_omega_alt <- graph_lp_one(patents_lp_omega_alt, "resid")
ggsave("../figures/local_projections/patents_lp_Int_logOmega.pdf", patents_lp_omega, width = 16, height = 9)
ggsave("../figures/local_projections/patents_lp_Int_logOmega_alt.pdf", patents_lp_omega_alt, width = 16, height = 9)
library(lmtest)
library(sandwich)
library(texreg)
library(dplyr)
# load residuals data
# load("../data/cleaned/resid_results_1997_2022.RData")
# Load BEA Data, and clean it
load("../data/cleaned/BEA_ILPA_data.RData") # pre-cleaned in cleaning code
columns_to_abs <- c(
"delta_software_1", "delta_software_5", "delta_software_10",
"delta_it_1", "delta_it_5", "delta_it_10",
"delta_compq_1", "delta_compq_5", "delta_compq_10"
)
invisible(lapply(columns_to_abs, function(col) {
BEA_ILPA_data[[paste0("abs_", col)]] <<- abs(BEA_ILPA_data[[col]])
}))
# Subset to only include when all delta_As aren't missing (so 2007 on)
BEA_ILPA_data$year <- as.character(BEA_ILPA_data$year)
regression_data <- resid_results %>%
select(Code, year, delta_1, delta_1_resid, delta_logPratio_1_II)
# generate absolute values
regression_data$abs_delta_1 <- abs(regression_data$delta_1)
regression_data$abs_delta_1_resid <- abs(regression_data$delta_1_resid)
regression_data$abs_delta_logPratio_1 <- abs(regression_data$delta_logPratio_1)
# recover maximum by Code-year for abs_delta_1, abs_delta_1_resid, etc...
regression_data_sum <- regression_data %>%
group_by(Code, year) %>%
summarise(
sum_delta_1 = sum(abs_delta_1, na.rm = TRUE),
sum_delta_1_resid = sum(abs_delta_1_resid, na.rm = TRUE)
)
regression_data_sum <- merge(regression_data_sum, BEA_ILPA_data, by = c("Code", "year"))
# Define formulas for regression
formulas <- list(
sum_delta_1 ~ abs_delta_software_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_software_1 + factor(year) + factor(Code),
sum_delta_1 ~ abs_delta_it_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_it_1 + factor(year) + factor(Code),
sum_delta_1 ~ abs_delta_compq_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_compq_1 + factor(year) + factor(Code)
)
formula_names <- c(
"sum_1_software_abs",
"sum_resid_1_software_abs",
"sum_1_it_abs",
"sum_resid_1_it_abs",
"sum_1_compq_abs",
"sum_resid_1_compq_abs"
)
results <- lapply(formulas, reg_wrapper, data = regression_data_sum)
names(results) <- formula_names
#######################
# Slides regression
#######################
coef_map <- list(
"abs_delta_software_1" = "Correlation",
"abs_delta_it_1" = "Correlation",
"abs_delta_compq_1" = "Correlation",
"abs_delta_software_5" = "Correlation",
"abs_delta_it_5" = "Correlation",
"abs_delta_compq_5" = "Correlation",
"abs_delta_software_10" = "Correlation",
"abs_delta_it_10" = "Correlation",
"abs_delta_compq_10" = "Correlation")
#######################
# OG regressions comparison
#######################
texreg(list(results[['sum_resid_1_software_abs']][[1]], results[['sum_resid_1_compq_abs']][[1]], results[['sum_resid_1_it_abs']][[1]]), override.se = list(results[['sum_resid_1_software_abs']][[2]], results[['sum_resid_1_compq_abs']][[2]], results[['sum_resid_1_it_abs']][[2]]), override.pvalues = list(results[['sum_resid_1_software_abs']][[3]], results[['sum_resid_1_compq_abs']][[3]], results[['sum_resid_1_it_abs']][[3]]), custom.coef.map = coef_map, custom.model.names = c("Software", "Computer", "IT"), include.rsquared = FALSE, include.adjrs = FALSE, stars = c(.1, .05, .01), table = FALSE, file = "../tables/og_resid_Int_mainresults_1yr.tex")
texreg(list(results[['sum_resid_1_software_abs']][[1]], results[['sum_resid_1_compq_abs']][[1]], results[['sum_resid_1_it_abs']][[1]]), override.se = list(results[['sum_resid_1_software_abs']][[2]], results[['sum_resid_1_compq_abs']][[2]], results[['sum_resid_1_it_abs']][[2]]), override.pvalues = list(results[['sum_resid_1_software_abs']][[3]], results[['sum_resid_1_compq_abs']][[3]], results[['sum_resid_1_it_abs']][[3]]), custom.coef.map = coef_map, custom.model.names = c("Software", "Computer", "IT"), include.rsquared = FALSE, include.adjrs = FALSE, stars = c(.1, .05, .01), table = FALSE)
library(lmtest)
library(sandwich)
library(texreg)
library(dplyr)
# load residuals data
# Load BEA Data, and clean it
load("../data/cleaned/BEA_ILPA_data.RData") # pre-cleaned in cleaning code
columns_to_abs <- c(
"delta_software_1", "delta_software_5", "delta_software_10",
"delta_it_1", "delta_it_5", "delta_it_10",
"delta_compq_1", "delta_compq_5", "delta_compq_10"
)
invisible(lapply(columns_to_abs, function(col) {
BEA_ILPA_data[[paste0("abs_", col)]] <<- abs(BEA_ILPA_data[[col]])
}))
# Subset to only include when all delta_As aren't missing (so 2007 on)
BEA_ILPA_data$year <- as.character(BEA_ILPA_data$year)
regression_data <- resid_results %>%
select(Code, year, delta_1, delta_1_resid, delta_logPratio_1_II)
# generate absolute values
regression_data$abs_delta_1 <- abs(regression_data$delta_1)
regression_data$abs_delta_1_resid <- abs(regression_data$delta_1_resid)
regression_data$abs_delta_logPratio_1 <- abs(regression_data$delta_logPratio_1)
# recover maximum by Code-year for abs_delta_1, abs_delta_1_resid, etc...
regression_data_sum <- regression_data %>%
group_by(Code, year) %>%
summarise(
sum_delta_1 = sum(abs_delta_1, na.rm = TRUE),
sum_delta_1_resid = sum(abs_delta_1_resid, na.rm = TRUE)
)
regression_data_sum <- merge(regression_data_sum, BEA_ILPA_data, by = c("Code", "year"))
# Define formulas for regression
formulas <- list(
sum_delta_1 ~ abs_delta_software_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_software_1 + factor(year) + factor(Code),
sum_delta_1 ~ abs_delta_it_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_it_1 + factor(year) + factor(Code),
sum_delta_1 ~ abs_delta_compq_1 + factor(year) + factor(Code),
sum_delta_1_resid ~ abs_delta_compq_1 + factor(year) + factor(Code)
)
formula_names <- c(
"sum_1_software_abs",
"sum_resid_1_software_abs",
"sum_1_it_abs",
"sum_resid_1_it_abs",
"sum_1_compq_abs",
"sum_resid_1_compq_abs"
)
results <- lapply(formulas, reg_wrapper, data = regression_data_sum)
names(results) <- formula_names
#######################
# Slides regression
#######################
coef_map <- list(
"abs_delta_software_1" = "Correlation",
"abs_delta_it_1" = "Correlation",
"abs_delta_compq_1" = "Correlation",
"abs_delta_software_5" = "Correlation",
"abs_delta_it_5" = "Correlation",
"abs_delta_compq_5" = "Correlation",
"abs_delta_software_10" = "Correlation",
"abs_delta_it_10" = "Correlation",
"abs_delta_compq_10" = "Correlation")
#######################
# OG regressions comparison
#######################
texreg(list(results[['sum_resid_1_software_abs']][[1]], results[['sum_resid_1_compq_abs']][[1]], results[['sum_resid_1_it_abs']][[1]]), override.se = list(results[['sum_resid_1_software_abs']][[2]], results[['sum_resid_1_compq_abs']][[2]], results[['sum_resid_1_it_abs']][[2]]), override.pvalues = list(results[['sum_resid_1_software_abs']][[3]], results[['sum_resid_1_compq_abs']][[3]], results[['sum_resid_1_it_abs']][[3]]), custom.coef.map = coef_map, custom.model.names = c("Software", "Computer", "IT"), include.rsquared = FALSE, include.adjrs = FALSE, stars = c(.1, .05, .01), table = FALSE, file = "../tables/og_resid_Int_mainresults_1yr.tex")
library(ggplot2)
library(dplyr)
library(fixest)
library(xtable)
coef_names <- names(coef(model_delta_1))
delta_theta <- as.data.frame(coef(model_delta_1)[grep(":logPratio_1", coef_names, value = TRUE)])
colnames(delta_theta) <- "delta_theta"
theta <- as.data.frame(coef(model_delta_1)[grep(":delta_logPratio_1", coef_names, value = TRUE)])
colnames(theta) <- "theta"
# make dataframe of first quartile, median, third quartile for delta_theta and theta
quartiles <- c(0.25, 0.5, 0.75)
delta_theta_quartiles <- as.data.frame(apply(delta_theta, 2, quantile, probs = quartiles))
theta_quartiles <- as.data.frame(apply(theta, 2, quantile, probs = quartiles))
merged_quartiles <- rbind(t(delta_theta_quartiles), t(theta_quartiles))
# round values to 2 decimal places
merged_quartiles <- round(merged_quartiles, 2)
rownames(merged_quartiles) <- c("$\\alpha_{it}$", "$\\beta_{it}$")
colnames(merged_quartiles) <- c("1st Quartile", "Median", "3rd Quartile")
merged_quartiles_table <- xtable(merged_quartiles, )
print(merged_quartiles_table, floating = FALSE, file = "../tables/elasticity_quartiles_Int.tex", sanitize.text.function=function(x){x})
# plot overlapping histograms of delta_theta and theta
delta_theta <- as.data.frame(delta_theta)
theta <- as.data.frame(theta)
delta_theta$coef <- "delta_theta"
theta$coef <- "theta"
names(delta_theta) <- c("value", "coef")
names(theta) <- c("value", "coef")
combined <- rbind(delta_theta, theta)
theta_hist <- ggplot(combined, aes(x = value, fill = coef)) +
geom_histogram(position = "identity", alpha = .25, binwidth = .1) +
theme_minimal() +
labs(title = "", x = "", y = "Frequency", fill = "") +
theme(text = element_text(family = "serif", size = 32), legend.position = "bottom") + coord_cartesian(xlim = c(-2, 2)) +
scale_fill_manual(values = c("red", "blue"), labels = c(expression(alpha[italic("it")]), expression(beta[italic("it")])))
ggsave("../figures/histograms/elasticity_coef_hist.pdf", theta_hist, width = 16, height = 9)
# set R2
r2_1 <- r2(model_delta_1)["r2"]
# overlapping histograms of delta and delta_resid
library(ggplot2)
library(gridExtra)
library(scales)
lab1 = "Original"
lab2 = "Residualized"
colors <- setNames(hue_pal()(2), c(lab1, lab2))
plot_data <- resid_results %>%
filter(!is.na(delta_1) & !is.na(delta_1_resid) & !is.infinite(delta_1) & !is.infinite(delta_1_resid))
# set delta_1/delta_1_resid/delta_5/delta_5_resid/delta_10/delta_10_resid to NA if < cutoff
cutoff <- 0.01
plot_data$delta_1[abs(plot_data$delta_1) < cutoff] <- NA
plot_data$delta_1_resid[abs(plot_data$delta_1_resid) < cutoff] <- NA
# Overlapping histograms for delta_1 and delta_1_resid using frequency
p1 <- ggplot(plot_data) +
geom_histogram(aes(x = delta_1, y = ..density.., fill = lab1), binwidth = 0.01, alpha = 0.5) +
geom_histogram(aes(x = delta_1_resid, y = ..density.., fill = lab2), binwidth = 0.01, alpha = 0.5) +
xlim(-2, 2) +
theme_minimal() +
scale_fill_manual(values = colors) +
labs(x = expression(~Delta*log(tilde(a[ij]))~ ", 1yr"), y = "", fill = "", caption = paste("R^2: ", round(r2_1, 2))) +
theme(text = element_text(family = "serif", size = 32), legend.position = "bottom")
# Display the plots
ggsave("../figures/histograms/A_Int_resid_hist_1yr.pdf", p1, width = 16, height = 9)
p1
# load libraries
library(dplyr)
library(tidyr)
library(readxl)
library(fixest)
source("../code/helper_fncts.R")
# load data
load("../data/cleaned/resid_data_1999_2023_api.RData") # load non-api data
# remove NaNs
resid_data_clean <- resid_data_1999_2023 %>%
filter(!is.na(delta_1) & !is.infinite(delta_1))
# generate industry_year factor
resid_data_clean$industry_year <- factor(paste(resid_data_clean$Code, resid_data_clean$year, sep = "_"))
# run residualizing regression
model_delta_1 <- feols(delta_1 ~ industry_year + delta_logPratio_1_II:industry_year + logPratio_1_II:industry_year, data = resid_data_clean)
# store residuals
resid_results <- resid_data_clean
resid_results$delta_1_resid <- model_delta_1$residuals
save(resid_results, model_delta_1, file = "../data/cleaned/resid_results_1999_2023_api.RData")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/api_pull_Compustat.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/api_pull_Compustat.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/api_pull_Compustat.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/cleaning/clean_patents.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/cleaning/clean_patents.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/cleaning/clean_patents.R")
source("~/Library/CloudStorage/GoogleDrive-jacob.gosselin@u.northwestern.edu/My Drive/research_ideas/changing_network/code/cleaning/clean_patents.R")
